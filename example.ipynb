{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operaciones que realiza un mecanismo de atención"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se importan las librerías en el cabecero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special as sci\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El corpus en este caso es inicializado de forma aleatoria y representa a los embeddings ya con codificación posicional.\n",
    "En la práctica se pueden tomar estos embeddings de una librería como word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus shape: (3, 3)\n",
      "\n",
      "\n",
      "Corpus:\n",
      "[[0.285 0.037 0.61 ]\n",
      " [0.503 0.051 0.279]\n",
      " [0.908 0.24  0.145]]\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(42)  # Valor aleatorio de seed, el cual permite poder replicar los resultados\n",
    "corpus = np.around(np.random.rand(3,3),3)\n",
    "corpus.shape\n",
    "print(f\"Corpus shape: {corpus.shape}\\n\\n\")\n",
    "print(f\"Corpus:\\n{corpus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de los embeddings iniciales se obtienen 3 matrices, Q, K y V, donde cada una es una copia de dichos embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q shape: (3, 3)\n",
      "\n",
      "\n",
      "Q:\n",
      "[[0.285 0.037 0.61 ]\n",
      " [0.503 0.051 0.279]\n",
      " [0.908 0.24  0.145]]\n"
     ]
    }
   ],
   "source": [
    "Q = corpus.copy()\n",
    "K = corpus.copy()\n",
    "V = corpus.copy()\n",
    "\n",
    "print(f\"Q shape: {Q.shape}\\n\\n\")\n",
    "print(f\"Q:\\n{Q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso la matriz de pesos inicia de forma aleatoria, en la práctica estas matrices pueden ya estar dadas gracias a entrenamientos previos para ahorrar tiempo y entrenamiento o bien inicializarse de forma aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key weights: [[0.634 0.536 0.09 ]\n",
      " [0.835 0.321 0.187]\n",
      " [0.041 0.591 0.678]]\n",
      "\n",
      "\n",
      "Query weights: [[0.489 0.986 0.242]\n",
      " [0.672 0.762 0.238]\n",
      " [0.728 0.368 0.632]]\n",
      "\n",
      "\n",
      "Values weights: [[0.017 0.512 0.226]\n",
      " [0.645 0.174 0.691]\n",
      " [0.387 0.937 0.138]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W_Q = np.around(np.random.rand(3,3),3)\n",
    "W_K = np.around(np.random.rand(3,3),3)\n",
    "W_V = np.around(np.random.rand(3,3),3)\n",
    "\n",
    "print(f\"Key weights: {W_K}\\n\\n\")\n",
    "print(f\"Query weights: {W_Q}\\n\\n\")\n",
    "print(f\"Values weights: {W_V}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se multiplica cada matriz (Q,K,V) con su respectiva matriz de pesos.\n",
    "\n",
    "Dicha matriz de pesos puede ser incializada (y en este caso es así) de forma aleatoria, sin embargo, estos valores se pueden tener pre-entrenados, de tal manera que ahorramos el ajuste de estos pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key (Post adding weights): \n",
      "[[0.236595 0.525147 0.446149]\n",
      " [0.372926 0.450868 0.243969]\n",
      " [0.782017 0.649423 0.22491 ]]\n",
      "\n",
      "\n",
      "Query (Post adding weights): \n",
      "[[0.608309 0.533684 0.463296]\n",
      " [0.483351 0.637492 0.310192]\n",
      " [0.710852 1.131528 0.368496]]\n",
      "\n",
      "\n",
      "Values (Post adding weights): \n",
      "[[0.26478  0.723928 0.174157]\n",
      " [0.149419 0.527833 0.187421]\n",
      " [0.226351 0.642521 0.391058]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Q = np.dot(Q,W_Q)\n",
    "K = np.dot(K,W_K)\n",
    "V = np.dot(V,W_V)\n",
    "Q_original = corpus.copy()\n",
    "\n",
    "print(f\"Key (Post adding weights): \\n{K}\\n\\n\")\n",
    "print(f\"Query (Post adding weights): \\n{Q}\\n\\n\")\n",
    "print(f\"Values (Post adding weights): \\n{V}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tiene que realizar la siguiente operación: \n",
    "$$\\text{Attention(Q,K,V)}=\\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{res}=QK^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63088447, 0.58050514, 0.92649455],\n",
       "       [0.58752729, 0.54335613, 0.86175595],\n",
       "       [0.92680669, 0.86516656, 1.37361709]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.dot(Q,K.T)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{res}=\\frac{\\text{res}}{\\sqrt{d_k}}=\\frac{QK^T}{\\sqrt{d_k}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2575575 , 0.23699023, 0.37823981],\n",
       "       [0.23985701, 0.22182421, 0.35181039],\n",
       "       [0.37836724, 0.35320277, 0.56077683]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = res/np.sqrt(K.shape[0]+K.shape[1])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{res}=\\text{softmax}(\\text{res})=\\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum = [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "res = sci.softmax(res,axis=0)\n",
    "print(f\"Sum = {np.sum(res,axis=0)}\")\n",
    "# e_x = np.exp(res[:1] - np.max(res))\n",
    "# res = e_x / e_x.sum()\n",
    "# print(f\"Sum = {np.sum(res)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiplicación con los valores originales\n",
    "Esto se realiza para agregar la información que ya está contextualizada con la información original.\n",
    "\n",
    "Esto se hace con el objetivo de que la matriz original contenga ya la información contextual, es decir, los tokens (en este caso palabras) ya conocen su relación con el resto de palabras del corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08511458, 0.23291035, 0.05486685],\n",
       "       [0.04718863, 0.16726437, 0.05750547],\n",
       "       [0.08210473, 0.23219412, 0.1478717 ]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = res*V\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica un redondeo con el objetivo de hacer más fácil la visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0851, 0.2329, 0.0549],\n",
       "       [0.0472, 0.1673, 0.0575],\n",
       "       [0.0821, 0.2322, 0.1479]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.around(res,4)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capa de normalización\n",
    "\n",
    "Se puede ver en el diagrama de la arquitectura, que posterior a la capa de atención, hay una etapa denominada \"Add & Norm\" de color amarillo.\n",
    "\n",
    "Esto indica que suma el resultado obtenido con la matriz N (número de tokens) $\\times$ M (longitud del embedding) original y posteriormente se realiza una normalización. Esta normalización comúnmente es la denominada `layer_normalization`.\n",
    "\n",
    "Este proceso se muestra en las siguientes celdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_norm(x, epsilon=1e-6):\n",
    "    mean = np.mean(x, axis=1, keepdims=True)  # Mean across features\n",
    "    variance = np.var(x, axis=1, keepdims=True)  # Variance across features\n",
    "    normalized = (x - mean) / np.sqrt(variance + epsilon)  # Normalization\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = layer_norm(res+Q_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representación visual\n",
    "\n",
    "Se convierte en DataFrame con el fin de poder visualizar que cada embedding es una representación vectorial de los tokens y que el mecanismo de atención tiene como fin entender la relación que tienen cada palabra con las otras del corpus.\n",
    "\n",
    "Se puede ver que en la matriz, el valor que se encuentre en la coordenada (renglón, columna) será la representación de la relación entre tokens, en donde un valor más grande indica una relación más fuerte entre palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amo</th>\n",
       "      <th>el</th>\n",
       "      <th>queso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Amo</th>\n",
       "      <td>-0.386900</td>\n",
       "      <td>-0.984547</td>\n",
       "      <td>1.371447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el</th>\n",
       "      <td>1.324032</td>\n",
       "      <td>-1.092278</td>\n",
       "      <td>-0.231754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queso</th>\n",
       "      <td>1.370163</td>\n",
       "      <td>-0.381810</td>\n",
       "      <td>-0.988353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Amo        el     queso\n",
       "Amo   -0.386900 -0.984547  1.371447\n",
       "el     1.324032 -1.092278 -0.231754\n",
       "queso  1.370163 -0.381810 -0.988353"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.DataFrame(res)\n",
    "res_df.columns=[\"Amo\",\"el\",\"queso\"]\n",
    "res_df.index=[\"Amo\",\"el\",\"queso\"]\n",
    "res_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algoritmos_meta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
