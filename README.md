# Simulación del mecanismo de atención 
El propósito de este cuaderno de python es mostrar el funcionamiento y cálculos necesarios dentro de un mecanismo de atención. 

Es importante mencionar que este funcionamiento es meramente ilustrativo, ya que como se menciona en el curso dado en CADS, hay pasos importantes los cuales no son desarrollados, tales como la codificación posicional o la obtención de una tokenización real, la cual puede ser obtenida, junto con los embeddings correspondientes gracias a otras librerías o APIs como Word2Vec. Además, de omitir etapas como el procesamiento paralelo que tantas ventajas otorga al modelo del Transformer.

Esperando que este notebook sea de apoyo para cualquiera, y enviando mis mejores deseos!
